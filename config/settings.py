"""
KonfigÃ¼rasyon ayarlarÄ± modÃ¼lÃ¼.
"""

import os
from dotenv import load_dotenv
from typing import Optional

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

class Settings:
    """Uygulama ayarlarÄ± sÄ±nÄ±fÄ±."""
    
    def __init__(self):
        self.groq_api_key: Optional[str] = os.getenv("GROQ_API_KEY")
        # GerÃ§ek Groq modellerini kullanÄ±yoruz
        self.text_model: str = "llama-3.3-70b-versatile"  # En yeni ve gÃ¼Ã§lÃ¼ Llama 3.3
        self.vision_model: str = "llama-3.2-90b-vision-preview"  # En gÃ¼Ã§lÃ¼ vision model
        self.reasoning_model: str = "llama-3.1-405b-reasoning"  # Reasoning iÃ§in
        self.tool_model: str = "llama-3.3-70b-versatile"  # Tool kullanÄ±mÄ± iÃ§in gÃ¼ncel model
        self.max_tokens: int = 8192  # Maverick iÃ§in maksimum
        self.temperature: float = 0.7
        self.gradio_share: bool = False
        self.gradio_port: int = 7862
        
        # Llama 3.3 70B Seviye Prompt-Based Agent System
        self.system_prompt: str = """Sen Llama 3.3 70B seviyesinde geliÅŸmiÅŸ bir AI Assistant'sÄ±n. LangChain ile entegre Ã§alÄ±ÅŸÄ±p tool'larÄ± prompt engineering ile yÃ¶netiyorsun.

ğŸ§  LLAMA 3.3 YETENEKLERÄ°N:
- Ã‡ok katmanlÄ± mantÄ±klÄ± dÃ¼ÅŸÃ¼nme (reasoning)
- Tool'larÄ± prompt ile akÄ±llÄ±ca tetikleme
- Otomatik context switch ve dil algÄ±lama
- GÃ¶rsel analiz ve OCR yetenekleri
- GeliÅŸmiÅŸ problem Ã§Ã¶zme algoritmalarÄ±

ï¿½ï¸ TOOL MANAGEMENT LOGIC:
KullanÄ±cÄ± mesajÄ±nÄ± analiz et ve gerekli tool'larÄ± akÄ±llÄ±ca seÃ§:

1. ğŸ• "Saat kaÃ§?", "bugÃ¼n ne gÃ¼nÃ¼", "tarih" â†’ get_current_time tool'unu Ã§aÄŸÄ±r
2. ğŸ“Š "analiz et", "kaÃ§ kelime", "istatistik" â†’ text_analyzer tool'unu Ã§aÄŸÄ±r
3. ğŸ“ "Ã¶zetle", "kÄ±salt", "summary" â†’ text_summarizer tool'unu Ã§aÄŸÄ±r
4. ğŸŒ "hangi dil", "language", "dil analizi" â†’ language_detector tool'unu Ã§aÄŸÄ±r
5. ğŸ” "ara", "search", "hava durumu", "bilgi" â†’ web_search tool'unu Ã§aÄŸÄ±r

ğŸ¯ SMART WORKFLOW:
1. User input analiz et
2. Uygun tool(s) seÃ§ ve sÄ±rayla Ã§aÄŸÄ±r
3. Tool Ã§Ä±ktÄ±larÄ±nÄ± Maverick seviyede entegre et
4. KullanÄ±cÄ±nÄ±n diline ve tonuna uygun yanÄ±t Ã¼ret
5. Ekstra deÄŸer katacak insight'lar ekle

ğŸŒ MULTI-LANGUAGE RESPONSE:
- TÃ¼rkÃ§e: Samimi, detaylÄ± ve emoji ile zengin
- English: Professional, structured and informative
- FranÃ§ais: Ã‰lÃ©gant et informatif avec style
- Deutsch: PrÃ¤zise und methodisch

ğŸ–¼ï¸ VISION CAPABILITIES:
GÃ¶rsel geldiÄŸinde:
1. DetaylÄ± visual analysis
2. OCR ve text extraction
3. Context-aware interpretation
4. Technical details assessment
5. Cultural/contextual insights

âš¡ LLAMA 3.3 SPEED & ACCURACY:
- HÄ±zlÄ± tool selection
- Parallel thinking processes
- Error prevention & correction
- Context-aware responses
- Learning from conversation history

Sen sadece bir AI deÄŸil, Llama 3.3 seviye problem solver'sÄ±n! ğŸš€"""
    
    def get_available_models(self) -> dict:
        """Mevcut model listesi."""
        return {
            "text_models": [
                "llama-3.3-70b-versatile",
                "llama-3.3-70b-specdec", 
                "llama-3.1-70b-versatile",
                "llama-3.1-405b-reasoning",
                "llama3-groq-70b-8192-tool-use-preview",
                "llama3-70b-8192"
            ],
            "vision_models": [
                "models/gemini-2.0-flash-lite"
            ]
        }
    
    def switch_model(self, model_name: str, model_type: str = "text"):
        """Model deÄŸiÅŸtir."""
        available = self.get_available_models()
        if model_type == "text" and model_name in available["text_models"]:
            self.text_model = model_name
            return True
        elif model_type == "vision" and model_name in available["vision_models"]:
            self.vision_model = model_name
            return True
        return False
        
    def validate(self) -> bool:
        """AyarlarÄ±n geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eder."""
        if not self.groq_api_key:
            raise ValueError("GROQ_API_KEY environment variable is required")
        return True

# Global settings instance
settings = Settings()
