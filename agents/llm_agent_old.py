"""
LLaMA 4 Prompt-Based AI Agent - Tool'suz tamamen prompt engineering ile Ã§alÄ±ÅŸÄ±r
"""

import os
import base64
import io
from PIL import Image
from datetime import datetime
from typing import Optional, Dict, Any, List, Tuple
from groq import Groq
from config.settings import Settings

import logging

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LLMAgent:
    """LLaMA 4 Prompt-Based AI Agent - Tool'suz tamamen prompt engineering ile Ã§alÄ±ÅŸÄ±r"""
    
    def __init__(self):
        self.settings = Settings()
        self.client = None
        self.conversation_history: List[Dict[str, Any]] = []
        self.current_text_model = self.settings.text_model
        self.current_vision_model = self.settings.vision_model
        self._initialize_client()
        
    def _initialize_client(self):
        """Groq istemcisini baÅŸlat"""
        if not self.settings.groq_api_key:
            raise ValueError("GROQ_API_KEY environment variable is required")
        
        self.client = Groq(api_key=self.settings.groq_api_key)
        logger.info(f"ğŸ¦™ LLaMA 4 Prompt-Based Agent baÅŸlatÄ±ldÄ±")
        logger.info(f"ğŸ“ Text Model: {self.current_text_model}")
        logger.info(f"ğŸ‘ï¸ Vision Model: {self.current_vision_model}")
    
    def switch_model(self, text_model: str, vision_model: str):
        """Model deÄŸiÅŸtir"""
        old_text = self.current_text_model
        old_vision = self.current_vision_model
        
        self.current_text_model = text_model
        self.current_vision_model = vision_model
        
        logger.info(f"ğŸ”„ Model deÄŸiÅŸtirildi:")
        logger.info(f"   Text: {old_text} â†’ {text_model}")
        logger.info(f"   Vision: {old_vision} â†’ {vision_model}")
        
        return f"âœ… Modeller gÃ¼ncellendi!\nï¿½ Text: {text_model}\nğŸ‘ï¸ Vision: {vision_model}"
    
    def _get_current_time_info(self) -> str:
        """Mevcut zaman bilgisini al (prompt iÃ§in)"""
        now = datetime.now()
        turkish_months = [
            "Ocak", "Åubat", "Mart", "Nisan", "MayÄ±s", "Haziran",
            "Temmuz", "AÄŸustos", "EylÃ¼l", "Ekim", "KasÄ±m", "AralÄ±k"
        ]
        turkish_days = [
            "Pazartesi", "SalÄ±", "Ã‡arÅŸamba", "PerÅŸembe", "Cuma", "Cumartesi", "Pazar"
        ]
        
        month_name = turkish_months[now.month - 1]
        day_name = turkish_days[now.weekday()]
        
        return f"Åu anki zaman: {now.day} {month_name} {now.year}, {day_name}, {now.hour:02d}:{now.minute:02d}"
    
    def _create_enhanced_prompt(self, user_message: str, has_image: bool = False) -> str:
        """LLaMA 4 iÃ§in geliÅŸmiÅŸ prompt oluÅŸtur"""
        time_info = self._get_current_time_info()
        
        base_context = f"""
[SISTEM BÄ°LGÄ°SÄ°]
{time_info}
Model: LLaMA 4 Prompt-Based System
Yetenek: Pure prompt engineering ile tÃ¼m iÅŸlemler

[KULLANICI MESAJI]
{user_message}

[GÃ–REV]
YukarÄ±daki kullanÄ±cÄ± mesajÄ±nÄ± analiz et ve ÅŸu kurallara gÃ¶re yanÄ±t ver:

1. ğŸ• ZAMAN SORULARI: "saat kaÃ§", "bugÃ¼n ne gÃ¼nÃ¼", "tarih" gibi ifadeler varsa:
   - YukarÄ±daki sistem zamanÄ±nÄ± kullan
   - TÃ¼rkÃ§e format: "ğŸ“… BugÃ¼n: [gÃ¼n] [ay] [yÄ±l], [gÃ¼n adÄ±]"
   - "ğŸ• Saat: [saat]:[dakika]" formatÄ± kullan

2. ğŸ“Š METÄ°N ANALÄ°ZÄ°: "analiz et", "say", "deÄŸerlendir" ifadeleri varsa:
   - Kelime/karakter/cÃ¼mle sayÄ±sÄ±nÄ± hesapla
   - Dil tespiti yap
   - Ton analizi yap (resmi/samimi/nÃ¶tr)
   - JSON formatÄ±nda dÃ¼zenle

3. ğŸ“ Ã–ZETLEME: "Ã¶zetle", "kÄ±salt", "summary" ifadeleri varsa:
   - Ana fikirleri koru
   - Ã–nemli detaylarÄ± dahil et
   - Ã–zet oranÄ±nÄ± belirt

4. ğŸŒ DÄ°L TESPÄ°TÄ°: KullanÄ±cÄ±nÄ±n dilini otomatik algÄ±la:
   - TÃ¼rkÃ§e â†’ Samimi ve detaylÄ± yanÄ±t
   - English â†’ Professional response
   - FranÃ§ais â†’ RÃ©ponse Ã©lÃ©gante
   - Deutsch â†’ PrÃ¤zise Antwort

5. ğŸ’¬ GENEL SOHBET: YukarÄ±dakiler dÄ±ÅŸÄ±nda:
   - KullanÄ±cÄ±nÄ±n dilinde yanÄ±tla
   - YardÄ±mcÄ± ve bilgili ol
   - Emoji kullanarak samimi yap
"""

        if has_image:
            base_context += """
6. ğŸ–¼ï¸ GÃ–RSEL ANALÄ°Z: GÃ¶rsel mevcut:
   - Ana objeleri tanÄ±mla
   - Renk ve kompozisyonu aÃ§Ä±kla
   - YazÄ±larÄ± oku ve Ã§evir
   - Teknik detaylarÄ± analiz et
   - BaÄŸlamsal yorumlar yap
   - DetaylÄ± ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ yanÄ±t ver
"""

        return base_context

    def process_message(self, message: str, image=None) -> str:
        """LLaMA 4 ile mesajÄ± iÅŸle - Tamamen prompt-based"""
        try:
            # GÃ¶rsel var mÄ± kontrol et
            has_image = image is not None
            
            if has_image:
                return self._process_with_vision(message, image)
            else:
                return self._process_text_only(message)
                
        except Exception as e:
            error_msg = f"âŒ LLaMA 4 iÅŸlem hatasÄ±: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    def _process_text_only(self, message: str) -> str:
        """Sadece metin iÃ§in LLaMA 4 iÅŸlemi"""
        enhanced_prompt = self._create_enhanced_prompt(message)
        
        # KonuÅŸma geÃ§miÅŸini ekle
        messages = [
            {"role": "system", "content": self.settings.system_prompt},
            {"role": "user", "content": enhanced_prompt}
        ]
        
        # Son birkaÃ§ mesajÄ± da ekle (context iÃ§in)
        if self.conversation_history:
            recent_history = self.conversation_history[-4:]  # Son 4 mesaj
            for hist in recent_history:
                if "role" in hist and "content" in hist:
                    messages.insert(-1, {
                        "role": hist["role"],
                        "content": hist["content"][:500]  # KÄ±salt
                    })
        
        # LLaMA 4 ile Ã§aÄŸrÄ± yap
        try:
            completion = self.client.chat.completions.create(
                model=self.current_text_model,
                messages=messages,
                max_tokens=self.settings.max_tokens,
                temperature=self.settings.temperature,
                stream=False
            )
            
            response = completion.choices[0].message.content
            
            # KonuÅŸma geÃ§miÅŸine ekle
            self.conversation_history.append({
                "role": "user",
                "content": message,
                "timestamp": datetime.now().isoformat()
            })
            self.conversation_history.append({
                "role": "assistant", 
                "content": response,
                "timestamp": datetime.now().isoformat(),
                "model": self.current_text_model
            })
            
            return response
            
        except Exception as e:
            return f"âŒ LLaMA 4 API hatasÄ±: {str(e)}"
    
    def _process_with_vision(self, message: str, image) -> str:
        """GÃ¶rsel analizi iÃ§in Gemini Vision API kullanÄ±lÄ±r"""
        try:
            import requests
            import json
            gemini_api_key = os.getenv("GEMINI_API_KEY")
            if not gemini_api_key:
                return "âŒ GÃ¶rsel analizi iÃ§in Gemini API anahtarÄ± bulunamadÄ±. LÃ¼tfen .env dosyanÄ±za GEMINI_API_KEY ekleyin."
            # GÃ¶rseli base64'e Ã§evir
            if hasattr(image, 'name'):
                img = Image.open(image.name)
            else:
                img = image
            img.thumbnail((1536, 1536), Image.Resampling.LANCZOS)
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=95)
            image_bytes = buffer.getvalue()
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            # Gemini API'ya istek
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-vision:generateContent?key={gemini_api_key}"
            prompt = self._create_enhanced_prompt(message, has_image=True)
            data = {
                "contents": [
                    {
                        "parts": [
                            {"text": prompt},
                            {"inline_data": {"mime_type": "image/jpeg", "data": image_base64}}
                        ]
                    }
                ]
            }
            headers = {"Content-Type": "application/json"}
            response = requests.post(url, headers=headers, data=json.dumps(data), timeout=60)
            if response.status_code == 200:
                result = response.json()
                gemini_text = result["candidates"][0]["content"]["parts"][0]["text"]
                # GeÃ§miÅŸe ekle
                self.conversation_history.append({
                    "role": "user",
                    "content": f"{message} [ğŸ“· GÃ¶rsel eklendi]",
                    "timestamp": datetime.now().isoformat()
                })
                self.conversation_history.append({
                    "role": "assistant",
                    "content": gemini_text,
                    "timestamp": datetime.now().isoformat(),
                    "model": "gemini-pro-vision"
                })
                return gemini_text
            else:
                return f"âŒ Gemini Vision API hatasÄ±: {response.status_code} - {response.text}"
        except Exception as e:
            return f"âŒ Gemini Vision API hata: {str(e)}"
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """KonuÅŸma geÃ§miÅŸini al"""
        return self.conversation_history
    
    def clear_memory(self):
        """KonuÅŸma geÃ§miÅŸini temizle - eski interface uyumluluÄŸu iÃ§in"""
        return self.clear_history()
    
    def clear_history(self):
        """KonuÅŸma geÃ§miÅŸini temizle"""
        self.conversation_history.clear()
        logger.info("ğŸ—‘ï¸ KonuÅŸma geÃ§miÅŸi temizlendi!")
        return "ğŸ—‘ï¸ KonuÅŸma geÃ§miÅŸi temizlendi!"
    
    def get_agent_info(self) -> str:
        """Agent bilgilerini al"""
        return f"""
ğŸ¦™ **LLaMA 4 Prompt-Based Agent**

ğŸ“Š **Aktif Modeller:**
- ğŸ“ Text: `{self.current_text_model}`
- ğŸ‘ï¸ Vision: `{self.current_vision_model}`

ğŸ¯ **Ã–zellikler:**
- âœ… Tamamen prompt-based (tool yok)
- âœ… Otomatik dil algÄ±lama
- âœ… AkÄ±llÄ± zaman/tarih iÅŸlemi
- âœ… Metin analizi ve Ã¶zetleme
- âœ… GÃ¶rsel analiz (OCR dahil)
- âœ… Ã‡ok dilli destek

ğŸ’¬ **KonuÅŸma GeÃ§miÅŸi:** {len(self.conversation_history)} mesaj

ArtÄ±k manuel tool'lar yok! Her ÅŸey LLaMA 4'Ã¼n doÄŸal yetenekleri ile yapÄ±lÄ±yor! ğŸš€
"""
