"""
Llama 3.3 70B + LangChain Prompt-Based AI Agent
Tool'lar Llama 3.3 ile prompt engineering entegrasyonu ile Ã§alÄ±ÅŸÄ±r
"""

import os
import base64
import io
from PIL import Image
from datetime import datetime
from typing import Optional, Dict, Any, List, Tuple
from groq import Groq
from config.settings import Settings

# LangChain imports - geri eklendi!
from langchain.agents import initialize_agent, AgentType
from langchain.memory import ConversationBufferWindowMemory
from langchain_groq import ChatGroq
from agents.tools import create_tools

import logging

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LLMAgent:
    """Llama 3.3 70B + LangChain Prompt-Based AI Agent"""
    
    def __init__(self):
        self.settings = Settings()
        self.groq_client = None
        self.langchain_llm = None
        self.agent = None
        self.memory = None
        self.current_text_model = self.settings.text_model
        self.current_vision_model = self.settings.vision_model
        self._initialize_systems()
        
    def _initialize_systems(self):
        """Groq ve LangChain sistemlerini Llama 3.3 ile baÅŸlat"""
        if not self.settings.groq_api_key:
            raise ValueError("GROQ_API_KEY environment variable is required")
        
        # Groq istemcisi (vision iÃ§in)
        self.groq_client = Groq(api_key=self.settings.groq_api_key)
        
        # LangChain + Groq LLM (Llama 3.3 ile tool entegrasyonu)
        self.langchain_llm = ChatGroq(
            groq_api_key=self.settings.groq_api_key,
            model_name=self.current_text_model,
            temperature=self.settings.temperature,
            max_tokens=self.settings.max_tokens
        )
        
        # KonuÅŸma hafÄ±zasÄ±
        self.memory = ConversationBufferWindowMemory(
            memory_key="chat_history",
            return_messages=True,
            k=10  # Son 10 mesajÄ± hatÄ±rla
        )
        
        # Tool'larÄ± yÃ¼kle
        tools = create_tools()
        
        # LangChain agent'Ä±nÄ± baÅŸlat - Meta-Llama Maverick seviyesi
        self.agent = initialize_agent(
            tools=tools,
            llm=self.langchain_llm,
            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
            memory=self.memory,
            verbose=True,  # Debug iÃ§in
            handle_parsing_errors=True,
            agent_kwargs={
                "system_message": self.settings.system_prompt,
                "input_variables": ["input", "chat_history", "agent_scratchpad"]
            }
        )
        
        logger.info(f"ğŸ¦™ Llama 3.3 + LangChain Agent baÅŸlatÄ±ldÄ±")
        logger.info(f"ğŸ“ Text Model: {self.current_text_model}")
        logger.info(f"ğŸ‘ï¸ Vision Model: {self.current_vision_model}")
        logger.info(f"ğŸ› ï¸ Tool Model: {self.current_text_model}")
    
    def switch_model(self, text_model: str, vision_model: str):
        """Model deÄŸiÅŸtir"""
        old_text = self.current_text_model
        old_vision = self.current_vision_model
        
        self.current_text_model = text_model
        self.current_vision_model = vision_model
        
        # LangChain LLM'i yeniden baÅŸlat
        self.langchain_llm = ChatGroq(
            groq_api_key=self.settings.groq_api_key,
            model_name=text_model,
            temperature=self.settings.temperature,
            max_tokens=self.settings.max_tokens
        )
        
        # Agent'Ä± yeniden baÅŸlat
        tools = create_tools()
        self.agent = initialize_agent(
            tools=tools,
            llm=self.langchain_llm,
            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
            memory=self.memory,
            verbose=True,
            handle_parsing_errors=True,
            agent_kwargs={
                "system_message": self.settings.system_prompt,
                "input_variables": ["input", "chat_history", "agent_scratchpad"]
            }
        )
        
        logger.info(f"ğŸ”„ Maverick Model deÄŸiÅŸtirildi:")
        logger.info(f"   Text: {old_text} â†’ {text_model}")
        logger.info(f"   Vision: {old_vision} â†’ {vision_model}")
        
        return f"âœ… Llama 3.3 Modeller gÃ¼ncellendi!\nğŸ“ Text: {text_model}\nğŸ‘ï¸ Vision: {vision_model}"
    
    def process_message(self, message: str, image=None) -> str:
        """Llama 3.3 ile mesajÄ± iÅŸle - LangChain + prompt-based tool entegrasyonu"""
        try:
            # GÃ¶rsel var mÄ± kontrol et
            if image is not None:
                return self._process_with_vision(message, image)
            else:
                return self._process_with_langchain(message)
                
        except Exception as e:
            error_msg = f"âŒ Llama 3.3 iÅŸlem hatasÄ±: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    def _process_with_langchain(self, message: str) -> str:
        """LangChain agent ile prompt-based tool entegrasyonu"""
        try:
            # LangChain agent'Ä±nÄ± Ã§aÄŸÄ±r - tool'lar otomatik olarak Ã§aÄŸrÄ±lacak
            response = self.agent.run(input=message)
            
            logger.info(f"âœ… Maverick LangChain yanÄ±t alÄ±ndÄ±")
            return response
            
        except Exception as e:
            error_msg = f"âŒ LangChain Agent hatasÄ±: {str(e)}"
            logger.error(error_msg)
            
            # Fallback: Direkt LLM Ã§aÄŸrÄ±sÄ±
            try:
                completion = self.groq_client.chat.completions.create(
                    model=self.current_text_model,
                    messages=[
                        {"role": "system", "content": self.settings.system_prompt},
                        {"role": "user", "content": message}
                    ],
                    max_tokens=self.settings.max_tokens,
                    temperature=self.settings.temperature
                )
                return f"âš ï¸ Fallback mode:\n\n{completion.choices[0].message.content}"
            except Exception as fallback_e:
                return f"âŒ Sistem hatasÄ±: {str(fallback_e)}"
    
    def _process_with_vision(self, message: str, image) -> str:
        """GÃ¶rsel analizi iÃ§in Meta-Llama Maverick vision"""
        try:
            # GÃ¶rseli iÅŸle
            if hasattr(image, 'name'):  # Gradio file objesi
                img = Image.open(image.name)
            else:
                img = image
            
            # Maverick iÃ§in optimize et
            img.thumbnail((1536, 1536), Image.Resampling.LANCZOS)
            
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=95)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            # Maverick Vision prompt
            enhanced_prompt = f"""
[META-LLAMA MAVERICK VISION ANALYSIS]

KullanÄ±cÄ± mesajÄ±: {message}

Bu gÃ¶rseli Maverick seviyede analiz et:

1. ğŸ” DETAYLI ANALÄ°Z:
   - Ana objeler ve kompozisyon
   - Renkler, Ä±ÅŸÄ±k, perspektif
   - Teknik kalite ve stil

2. ğŸ“– METIN OKUMA (OCR):
   - GÃ¶rseldeki tÃ¼m yazÄ±larÄ± oku
   - FarklÄ± dillerdeki metinleri Ã§evir
   - Tabela, logo, iÅŸaret vb. tanÄ±mla

3. ğŸ§  CONTEXT ANALYSÄ°S:
   - Bu gÃ¶rsel hangi amaÃ§la Ã§ekilmiÅŸ?
   - Hangi ortam, zaman, durum?
   - KÃ¼ltÃ¼rel ve sosyal context

4. ğŸ’¡ MAVERICK Ä°NSIGHT:
   - Dikkat Ã§eken detaylar
   - Gizli anlamlar veya semboller
   - Profesyonel deÄŸerlendirme

TÃ¼rkÃ§e'de detaylÄ± ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ yanÄ±t ver.
"""
            
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": enhanced_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ]
            
            completion = self.groq_client.chat.completions.create(
                model=self.current_vision_model,
                messages=messages,
                max_tokens=self.settings.max_tokens,
                temperature=self.settings.temperature
            )
            
            response = completion.choices[0].message.content
            logger.info("âœ… Maverick Vision analizi tamamlandÄ±")
            return response
            
        except Exception as e:
            return f"âŒ Meta-Llama Maverick Vision hatasÄ±: {str(e)}"
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """KonuÅŸma geÃ§miÅŸini al - LangChain memory'den"""
        if self.memory and hasattr(self.memory, 'chat_memory'):
            messages = self.memory.chat_memory.messages
            history = []
            for msg in messages:
                history.append({
                    "role": "human" if hasattr(msg, 'content') and msg.__class__.__name__ == "HumanMessage" else "assistant",
                    "content": msg.content,
                    "timestamp": datetime.now().isoformat()
                })
            return history
        return []
    
    def clear_memory(self):
        """KonuÅŸma geÃ§miÅŸini temizle - eski interface uyumluluÄŸu iÃ§in"""
        return self.clear_history()
    
    def clear_history(self):
        """LangChain memory'yi temizle"""
        if self.memory:
            self.memory.clear()
        logger.info("ğŸ—‘ï¸ Meta-Llama Maverick hafÄ±zasÄ± temizlendi!")
        return "ğŸ—‘ï¸ Meta-Llama Maverick hafÄ±zasÄ± temizlendi!"
    
    def get_agent_info(self) -> str:
        """Agent bilgilerini al"""
        tool_count = len(create_tools()) if create_tools() else 0
        memory_count = len(self.get_conversation_history())
        
        return f"""
ğŸ¦™ **Meta-Llama Maverick + LangChain Agent**

ğŸ“Š **Aktif Modeller:**
- ğŸ“ Text: `{self.current_text_model}`
- ğŸ‘ï¸ Vision: `{self.current_vision_model}`
- ğŸ› ï¸ Tool: `{self.settings.tool_model}`

ğŸ¯ **Maverick Ã–zellikleri:**
- âœ… LangChain framework entegrasyonu
- âœ… Prompt-based tool management
- âœ… Otomatik tool selection
- âœ… GeliÅŸmiÅŸ reasoning capabilities
- âœ… Vision analysis + OCR
- âœ… Multi-language support
- âœ… Conversation memory ({memory_count} mesaj)

ğŸ› ï¸ **Mevcut Tool'lar:** {tool_count} adet
- â° AkÄ±llÄ± zaman/tarih iÅŸlemi
- ğŸ“Š GeliÅŸmiÅŸ metin analizi  
- ğŸŒ Dil tespiti ve kÃ¼ltÃ¼rel analiz
- ğŸ“ AI-powered Ã¶zetleme
- ğŸ” Bilgi arama ve analiz

Meta-Llama Maverick seviyede reasoning + LangChain tool entegrasyonu! ğŸš€
"""
