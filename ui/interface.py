"""
Gradio arayÃ¼z modÃ¼lÃ¼.
"""

import gradio as gr
from typing import List, Tuple
import logging

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GradioInterface:
    """Gradio web arayÃ¼zÃ¼ sÄ±nÄ±fÄ±."""
    
    def __init__(self, agent):
        """ArayÃ¼zÃ¼ agent ile baÅŸlatÄ±r."""
        self.agent = agent
        self.interface = None
        self._create_interface()
    
    def _create_interface(self) -> None:
        """Gradio arayÃ¼zÃ¼nÃ¼ oluÅŸturur."""
        try:
            # CSS stilleri
            css = """
            .chat-container {
                max-height: 500px;
                overflow-y: auto;
            }
            .user-message {
                background-color: #e3f2fd;
                padding: 10px;
                margin: 5px;
                border-radius: 10px;
                text-align: right;
            }
            .bot-message {
                background-color: #f1f8e9;
                padding: 10px;
                margin: 5px;
                border-radius: 10px;
                text-align: left;
            }
            """
            
            with gr.Blocks(css=css, title="Llama 3.3 - AI Vision & Chat") as interface:
                gr.HTML("""
                <div style="text-align: center; margin-bottom: 20px;">
                    <h1>ğŸš€ CevapLlama</h1>
                    <p>Groq AI ile CevapLlama - geliÅŸmiÅŸ gÃ¶rsel analiz ve akÄ±llÄ± sohbet</p>
                </div>
                """)
                
                with gr.Row():
                    with gr.Column(scale=3):
                        # Chat arayÃ¼zÃ¼
                        chatbot = gr.Chatbot(
                            label="KonuÅŸma",
                            height=400,
                            show_label=True,
                            container=True,
                            bubble_full_width=False
                        )
                        
                        with gr.Row():
                            with gr.Column(scale=3):
                                user_input = gr.Textbox(
                                    label="MesajÄ±nÄ±z",
                                    placeholder="Merhaba! Bir soru sorun veya gÃ¶rsel yÃ¼kleyin...",
                                    lines=2
                                )
                            with gr.Column(scale=1):
                                image_input = gr.Image(
                                    label="GÃ¶rsel YÃ¼kle",
                                    type="pil",
                                    sources=["upload", "webcam"],
                                    height=100
                                )
                        
                        with gr.Row():
                            send_btn = gr.Button("GÃ¶nder", variant="primary", scale=2)
                            clear_btn = gr.Button("KonuÅŸmayÄ± Temizle", variant="secondary", scale=1)
                    
                    with gr.Column(scale=1):
                        # Model seÃ§ici
                        with gr.Accordion("ğŸš€ Model AyarlarÄ±", open=False):
                            text_model_dropdown = gr.Dropdown(
                                choices=[
                                    "llama-3.3-70b-versatile",  # En yeni Llama 3.3
                                    "llama-3.3-70b-specdec", 
                                    "llama-3.1-70b-versatile",
                                    "llama-3.1-405b-reasoning",
                                    "llama3-groq-70b-8192-tool-use-preview",
                                    "llama3-70b-8192"
                                ],
                                value="llama-3.3-70b-versatile",  # Default en yeni model
                                label="Text Model",
                                interactive=True
                            )
                            vision_model_dropdown = gr.Dropdown(
                                choices=[
                                    "models/gemini-2.0-flash-lite"
                                ],
                                value="models/gemini-2.0-flash-lite",
                                label="Vision Model (Gemini 2.0 Flash Lite)",
                                interactive=False
                            )
                        
                        # Bilgi paneli
                        gr.HTML("""
                        <div style="padding: 20px; background-color: #222; border-radius: 10px; color: #f5f5f5;">
                            <h3>ğŸš€ Llama 3.3 70B Yetenekleri</h3>
                            <ul>
                                <li>ï¿½ 17B parametre Maverick model</li>
                                <li>ğŸ§  128K context window</li>
                                <li>ï¿½ğŸ–¼ï¸ 90B param gÃ¶rsel analiz</li>
                                <li>ğŸŒ Ã‡oklu dil desteÄŸi</li>
                                <li>ğŸ”— Groq AI hÄ±zlÄ± inference</li>
                                <li>ğŸ› ï¸ LangChain tool entegrasyonu</li>
                                <li>â° Zaman ve tarih bilgisi</li>
                                <li>ğŸ“Š GeliÅŸmiÅŸ metin analizi</li>
                                <li>ğŸ“ AI-powered Ã¶zetleme</li>
                                <li>ğŸ” Otomatik dil algÄ±lama</li>
                            </ul>
                            
                            <h3>ğŸ’¡ Ã–rnek KullanÄ±m</h3>
                            <ul>
                                <li>"Bu gÃ¶rselde ne var?"</li>
                                <li>"Saat kaÃ§?"</li>
                                <li>"Bu metni analiz et: ..."</li>
                                <li>"What time is it?" (Ä°ngilizce)</li>
                                <li>"RÃ©sume ce texte" (FransÄ±zca)</li>
                                <li>GÃ¶rsel + "AÃ§Ä±kla"</li>
                            </ul>
                            
                            <p><strong>ğŸš€ Powered by Llama 3.3 70B!</strong></p>
                        </div>
                        """)
                
                # Event handlers
                def process_message(message: str, image, history: List[List[str]]) -> Tuple[List[List[str]], str, None]:
                    """
                    KullanÄ±cÄ± mesajÄ±nÄ± iÅŸler. EÄŸer saat veya tarih soruluyorsa, local date/time bilgisini prompt'a ekler.
                    """
                    try:
                        import re
                        import datetime
                        if not message.strip() and image is None:
                            return history, "", None
                        
                        # GÃ¶rsel yÃ¼klendiyse Gemini Vision API ile analiz et
                        if image is not None:
                            try:
                                import os
                                import requests
                                import json
                                import base64
                                import io
                                from PIL import Image
                                gemini_api_key = os.getenv("GEMINI_API_KEY")
                                if not gemini_api_key:
                                    error_response = "âŒ GÃ¶rsel analizi iÃ§in Gemini API anahtarÄ± bulunamadÄ±. LÃ¼tfen .env dosyanÄ±za GEMINI_API_KEY ekleyin."
                                    display_message = message if message.strip() else "GÃ¶rsel analizi"
                                    history.append([display_message, error_response])
                                    return history, "", None
                                # GÃ¶rseli base64'e Ã§evir
                                if hasattr(image, 'name'):
                                    img = Image.open(image.name)
                                else:
                                    img = image
                                img.thumbnail((1536, 1536), Image.Resampling.LANCZOS)
                                buffer = io.BytesIO()
                                img.save(buffer, format='JPEG', quality=95)
                                image_bytes = buffer.getvalue()
                                image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                                url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key={gemini_api_key}"
                                prompt = message or "Bu resmi aÃ§Ä±kla"
                                data = {
                                    "contents": [
                                        {
                                            "parts": [
                                                {"text": prompt},
                                                {"inline_data": {"mime_type": "image/jpeg", "data": image_base64}}
                                            ]
                                        }
                                    ]
                                }
                                headers = {"Content-Type": "application/json"}
                                response = requests.post(url, headers=headers, data=json.dumps(data), timeout=60)
                                if response.status_code == 200:
                                    result = response.json()
                                    gemini_text = result["candidates"][0]["content"]["parts"][0]["text"]
                                    display_message = message if message.strip() else "GÃ¶rsel analizi"
                                    history.append([display_message, gemini_text])
                                    return history, "", None
                                else:
                                    error_response = f"âŒ Gemini Vision API hatasÄ±: {response.status_code} - {response.text}"
                                    display_message = message if message.strip() else "GÃ¶rsel analizi"
                                    history.append([display_message, error_response])
                                    return history, "", None
                            except Exception as e:
                                error_response = f"âŒ GÃ¶rsel analizi hatasÄ±: {str(e)}"
                                display_message = message if message.strip() else "GÃ¶rsel analizi"
                                history.append([display_message, error_response])
                                return history, "", None
                        
                        # Mesaj hazÄ±rla
                        display_message = message if message.strip() else "GÃ¶rsel analizi"
                        
                        # Saat veya tarih sorusu mu?
                        time_patterns = [
                            r"saat[\s\?]*$", r"saat kaÃ§", r"what time", r"current time", r"time now", r"kaÃ§ saat", r"zaman nedir", r"date", r"tarih", r"bugÃ¼n ne", r"hangi gÃ¼n"
                        ]
                        is_time_query = any(re.search(pat, message.lower()) for pat in time_patterns)
                        prompt = message
                        if is_time_query:
                            now = datetime.datetime.now()
                            local_time = now.strftime("%d.%m.%Y %A %H:%M:%S")
                            # TÃ¼rkÃ§e ve Ä°ngilizce aÃ§Ä±klama ekle
                            ek = f"\nNot: Åu anki yerel saat ve tarih: {local_time} (LÃ¼tfen cevabÄ±nda bu bilgiyi kullan.)"
                            prompt = f"{message}\n{ek}"
                        
                        # Agent'tan yanÄ±t al
                        response = self.agent.process_message(prompt, image)
                        
                        # GeÃ§miÅŸe ekle
                        history.append([display_message, response])
                        
                        return history, "", None
                        
                    except Exception as e:
                        logger.error(f"Mesaj iÅŸleme hatasÄ±: {str(e)}")
                        error_response = f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"
                        history.append([message or "GÃ¶rsel", error_response])
                        return history, "", None
                
                def clear_conversation():
                    """KonuÅŸmayÄ± temizler."""
                    try:
                        self.agent.clear_memory()
                        return []
                    except Exception as e:
                        logger.error(f"Temizleme hatasÄ±: {str(e)}")
                        return []
                
                def change_text_model(model_name):
                    """Text modelini deÄŸiÅŸtirir."""
                    try:
                        from config.settings import settings
                        if settings.switch_model(model_name, "text"):
                            # Agent'Ä± yeniden baÅŸlat
                            self.agent._initialize_llms()
                            return f"âœ… Text model deÄŸiÅŸtirildi: {model_name}"
                        return "âŒ Model deÄŸiÅŸtirilemedi"
                    except Exception as e:
                        return f"âŒ Hata: {str(e)}"
                
                def change_vision_model(model_name):
                    """Vision modelini deÄŸiÅŸtirir."""
                    try:
                        from config.settings import settings
                        if settings.switch_model(model_name, "vision"):
                            # Agent'Ä± yeniden baÅŸlat
                            self.agent._initialize_llms()
                            return f"âœ… Vision model deÄŸiÅŸtirildi: {model_name}"
                        return "âŒ Model deÄŸiÅŸtirilemedi"
                    except Exception as e:
                        return f"âŒ Hata: {str(e)}"
                
                # Event bindings
                send_btn.click(
                    fn=process_message,
                    inputs=[user_input, image_input, chatbot],
                    outputs=[chatbot, user_input, image_input]
                )
                
                user_input.submit(
                    fn=process_message,
                    inputs=[user_input, image_input, chatbot],
                    outputs=[chatbot, user_input, image_input]
                )
                
                clear_btn.click(
                    fn=clear_conversation,
                    outputs=[chatbot]
                )
                
                # Model deÄŸiÅŸtirme event'leri
                text_model_dropdown.change(
                    fn=change_text_model,
                    inputs=[text_model_dropdown],
                    outputs=[]
                )
                
                vision_model_dropdown.change(
                    fn=change_vision_model,
                    inputs=[vision_model_dropdown],
                    outputs=[]
                )
            
            self.interface = interface
            logger.info("Gradio arayÃ¼zÃ¼ baÅŸarÄ±yla oluÅŸturuldu")
            
        except Exception as e:
            logger.error(f"ArayÃ¼z oluÅŸturma hatasÄ±: {str(e)}")
            raise
    
    def launch(self, share: bool = False, port: int = 7860, max_tries: int = 10) -> None:
        """ArayÃ¼zÃ¼ baÅŸlatÄ±r. Port kullanÄ±mdaysa bir sonraki portu dener."""
        try:
            if not self.interface:
                raise ValueError("ArayÃ¼z oluÅŸturulmamÄ±ÅŸ")
            
            current_port = port
            for attempt in range(max_tries):
                try:
                    logger.info(f"ArayÃ¼z baÅŸlatÄ±lÄ±yor - Port: {current_port}, Share: {share}")
                    self.interface.launch(
                        share=share,
                        server_port=current_port,
                        server_name="0.0.0.0",
                        show_error=True,
                        quiet=False
                    )
                    return
                except Exception as e:
                    if "address already in use" in str(e).lower() or "Cannot find empty port" in str(e):
                        logger.warning(f"Port {current_port} kullanÄ±lÄ±yor, bir sonrakini deniyorum...")
                        current_port += 1
                    else:
                        logger.error(f"ArayÃ¼z baÅŸlatma hatasÄ±: {str(e)}")
                        raise
            logger.error(f"{max_tries} port denemesine raÄŸmen boÅŸ port bulunamadÄ±.")
            raise RuntimeError(f"{max_tries} port denemesine raÄŸmen boÅŸ port bulunamadÄ±.")
        except Exception as e:
            logger.error(f"ArayÃ¼z baÅŸlatma hatasÄ±: {str(e)}")
            raise
